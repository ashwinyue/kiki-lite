# Kiki å¯è§‚æµ‹æ€§ä¸é«˜å¹¶å‘å¢å¼ºæ–‡æ¡£

æœ¬æ–‡æ¡£ä»‹ç»åŸºäº AI å·¥ç¨‹å¸ˆè®­ç»ƒè¥å‚è€ƒå®ç°çš„ç”Ÿäº§çº§å¢å¼ºåŠŸèƒ½ã€‚

> **è·¯çº¿å›¾ï¼š** æŸ¥çœ‹åç»­å®ç°è®¡åˆ’ï¼Œè¯·å‚é˜… [ROADMAP.md](./ROADMAP.md)

---

## ğŸ“ æ–°å¢æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæ¨¡å—

| æ–‡ä»¶ | æè¿° | å‚è€ƒ |
|------|------|------|
| `app/observability/elk_handler.py` | ELK Logstash TCP æ—¥å¿—å¤„ç†å™¨ | week08/p41elk.py |
| `app/core/token_bucket.py` | ä»¤ç‰Œæ¡¶é™æµä¸­é—´ä»¶ | week09/3/p29é™æµä¸­é—´ä»¶ |
| `app/infra/cache.py` | Redis ç¼“å­˜åŸºç¡€è®¾æ–½ï¼ˆTTL æŠ–åŠ¨ã€åˆ†å¸ƒå¼é”ã€ç©¿é€é˜²æŠ¤ï¼‰ | week09/3/p30ç¼“å­˜ç­–ç•¥ |
| `app/agent/memory/window.py` | çª—å£è®°å¿†ï¼ˆToken é™åˆ¶ï¼‰ | week07/p07-windowMEM.py |
| `app/agent/retry.py` | å·¥å…·é‡è¯•æœºåˆ¶ | week07/p13-toolRetry.py |

### é…ç½®æ–‡ä»¶

| æ–‡ä»¶ | æè¿° |
|------|------|
| `config/prometheus.yml` | Prometheus æŠ“å–é…ç½® |
| `config/alerts/kiki_alerts.yml` | Prometheus å‘Šè­¦è§„åˆ™ |
| `config/logstash/logstash.conf` | Logstash ç®¡é“é…ç½® |
| `config/alertmanager.yml` | Alertmanager é…ç½® |
| `grafana/dashboards/kiki-dashboard.json` | Grafana ä»ªè¡¨æ¿ |
| `docker-compose.observability.yml` | å¯è§‚æµ‹æ€§æœåŠ¡æ ˆ |

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### 1. å¯åŠ¨å¯è§‚æµ‹æ€§æœåŠ¡æ ˆ

```bash
# å¯åŠ¨ ELK + Prometheus + Grafana
docker-compose -f docker-compose.observability.yml up -d

# è®¿é—®åœ°å€
# - Kibana: http://localhost:5601
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
```

### 2. å¯ç”¨ ELK æ—¥å¿—

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ï¼š

```bash
KIKI_ELK_ENABLED=true
KIKI_ELK_HOST=localhost
KIKI_ELK_PORT=5044
```

ç„¶ååœ¨ `app/main.py` ä¸­æ³¨å†Œï¼š

```python
from app.observability.elk_handler import setup_elk_logging

# åœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨
setup_elk_logging(logger)
```

### 3. å¯ç”¨ä»¤ç‰Œæ¡¶é™æµ

åœ¨ `app/main.py` ä¸­æ·»åŠ ä¸­é—´ä»¶ï¼š

```python
from app.core.token_bucket import TokenBucketRateLimiter

app.add_middleware(
    TokenBucketRateLimiter,
    rate_per_sec=10.0,      # 10 ä»¤ç‰Œ/ç§’
    burst_capacity=50,      # çªå‘å®¹é‡ 50
    exempt_paths={"/health", "/metrics", "/docs"},
)
```

### 5. ä½¿ç”¨å¢å¼ºç¼“å­˜

```python
from app.infra.cache import cached, cache_instance

# è£…é¥°å™¨æ–¹å¼
@cached(ttl=600, key_prefix="user")
async def get_user(user_id: int) -> User:
    return await db.fetch_user(user_id)

# å¼ºåˆ¶è·³è¿‡ç¼“å­˜
user = await get_user(123, _cache_bypass=True)

# ç›´æ¥ä½¿ç”¨ç¼“å­˜å®ä¾‹
await cache_instance.set("key", value, ttl=300)
value = await cache_instance.get("key")
```

---

## ğŸ“Š åŠŸèƒ½è¯¦è§£

### 1. ELK æ—¥å¿—å¤„ç†å™¨

**ç‰¹æ€§ï¼š**
- è‡ªåŠ¨é‡è¿æœºåˆ¶ï¼ˆæœ€å¤š 3 æ¬¡é‡è¯•ï¼‰
- çº¿ç¨‹å®‰å…¨ï¼ˆä½¿ç”¨ RLockï¼‰
- æ‰¹é‡å‘é€æ¨¡å¼
- é™çº§åˆ°æœ¬åœ°æ–‡ä»¶

**ä½¿ç”¨æ–¹å¼ï¼š**

```python
from app.observability.elk_handler import ELKHandler, BatchELKHandler

# åŸºç¡€å¤„ç†å™¨
handler = ELKHandler(
    host="localhost",
    port=5044,
    timeout=5.0,
    max_retries=3,
    enable_fallback=True,
)
logger.addHandler(handler)

# æ‰¹é‡å¤„ç†å™¨ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
batch_handler = BatchELKHandler(
    host="localhost",
    port=5044,
    batch_size=10,          # ç´¯ç§¯ 10 æ¡åå‘é€
    batch_timeout=5.0,      # æˆ– 5 ç§’åå‘é€
)
logger.addHandler(batch_handler)
```

**æ—¥å¿—æ ¼å¼ï¼š**

```json
{
  "@timestamp": "2025-01-31T10:30:45.123Z",
  "level": "INFO",
  "logger_name": "app.api.chat",
  "message": "å¤„ç†èŠå¤©è¯·æ±‚",
  "thread": 12345,
  "process": 6789,
  "source": {
    "file": "/app/api/chat.py",
    "line": 42,
    "function": "handle_chat"
  },
  "context": {
    "request_id": "abc-123",
    "user_id": "user-001",
    "session_id": "sess-xyz"
  }
}
```

---

### 2. ä»¤ç‰Œæ¡¶é™æµ

**ä¸ slowapi å¯¹æ¯”ï¼š**

| ç‰¹æ€§ | slowapi (Kiki åŸæœ‰) | TokenBucket (æ–°å¢) |
|------|---------------------|-------------------|
| ç®—æ³• | å›ºå®šçª—å£ | ä»¤ç‰Œæ¡¶ |
| çªå‘æ”¯æŒ | âŒ | âœ… |
| è‡ªå®šä¹‰é”® | âœ… | âœ… |
| å“åº”å¤´ | åŸºç¡€ | å®Œæ•´ (RFC 6585) |
| åˆ†å¸ƒå¼ | Redis | å†…å­˜ (å¯æ‰©å±•) |

**ä½¿ç”¨æ–¹å¼ï¼š**

```python
from app.core.token_bucket import (
    TokenBucketRateLimiter,
    PathBasedRateLimiter,
    RateLimitPolicy,
)

# æ–¹å¼ 1: å…¨å±€ä¸­é—´ä»¶
app.add_middleware(
    TokenBucketRateLimiter,
    rate_per_sec=10.0,
    burst_capacity=50,
    exempt_paths={"/health", "/docs"},
)

# æ–¹å¼ 2: åŸºäºè·¯å¾„çš„ä¸åŒç­–ç•¥
app.add_middleware(
    PathBasedRateLimiter,
    policies={
        "/api/v1/chat": RateLimitPolicy(rate=0.5, burst_capacity=10),   # 2 req/s
        "/api/v1/agents": RateLimitPolicy(rate=2.0, burst_capacity=20),  # 10 req/s
    },
    default_policy=RateLimitPolicy(rate=10.0, burst_capacity=50),
)

# æ–¹å¼ 3: è‡ªå®šä¹‰é”®ï¼ˆæŒ‰ç”¨æˆ·é™æµï¼‰
def user_key_func(request: Request) -> str:
    user_id = getattr(request.state, "user_id", None)
    return f"user:{user_id}" if user_id else f"ip:{request.client.host}"

app.add_middleware(
    TokenBucketRateLimiter,
    rate_per_sec=5.0,
    burst_capacity=20,
    key_func=user_key_func,
)
```

**å“åº”å¤´ï¼š**

```
X-RateLimit-Policy: token_bucket; rate=10.0/s; burst=50
X-RateLimit-Limit: 50
X-RateLimit-Remaining: 42
X-RateLimit-Reset: 3
Retry-After: 3  # ä»…é™æµæ—¶å‡ºç°
```

---

---

### 4. å¢å¼ºç¼“å­˜

**TTL æŠ–åŠ¨ï¼š**

```python
from app.infra.cache import RedisCache

cache = RedisCache(
    redis_url="redis://localhost:6379/0",
    default_ttl=300,
    jitter_percent=0.1,  # Â±10% æŠ–åŠ¨
)

# è®¾ç½®ç¼“å­˜ï¼ˆè‡ªåŠ¨æ·»åŠ æŠ–åŠ¨ï¼‰
await cache.set("key", "value", ttl=300)
# å®é™… TTL å¯èƒ½æ˜¯ 270 ~ 330 ç§’
```

**åˆ†å¸ƒå¼é”ï¼š**

```python
from app.infra.cache import DistributedLock

lock = DistributedLock(cache)

# æ–¹å¼ 1: æ‰‹åŠ¨ç®¡ç†
acquired = await lock.acquire("resource_name", timeout=10)
if acquired:
    try:
        # æ‰§è¡Œéœ€è¦ä¿æŠ¤çš„æ“ä½œ
        result = await expensive_operation()
    finally:
        await lock.release("resource_name")

# æ–¹å¼ 2: ä¸Šä¸‹æ–‡ç®¡ç†å™¨
async with lock:
    result = await expensive_operation()
```

**ç¼“å­˜ç©¿é€é˜²æŠ¤ï¼š**

```python
from app.infra.cache import CachePenetrationProtection

protection = CachePenetrationProtection(cache, null_ttl=60)

async def fetch_user(user_id: int):
    # æ•°æ®åº“æŸ¥è¯¢å‡½æ•°
    return await db.query(user_id)

# è‡ªåŠ¨å¤„ç†ç©ºå€¼ç¼“å­˜
result = await protection.get_or_fetch(
    f"user:{user_id}",
    fetch_user,
    ttl=300,
)
```

**ç¼“å­˜è£…é¥°å™¨ï¼š**

```python
from app.infra.cache import cached

@cached(
    ttl=600,                    # ç¼“å­˜ 10 åˆ†é’Ÿ
    key_prefix="prediction",     # é”®å‰ç¼€
    exclude_params=["debug"],    # æ’é™¤ debug å‚æ•°
)
async def get_prediction(model: str, features: list, debug: bool = False):
    # è®¡ç®—...
    return prediction

# å¼ºåˆ¶è·³è¿‡ç¼“å­˜
result = await get_prediction("model", [1,2,3], _cache_bypass=True)
```

---

## ğŸ“ˆ Grafana ä»ªè¡¨æ¿

å¯¼å…¥ä»ªè¡¨æ¿ï¼š`grafana/dashboards/kiki-dashboard.json`

**åŒ…å«çš„é¢æ¿ï¼š**

1. **è¯·æ±‚é€Ÿç‡ (QPS)** - æŒ‰æ–¹æ³•å’ŒçŠ¶æ€ç åˆ†ç»„
2. **P95 å“åº”æ—¶é—´** - å®æ—¶ gauge
3. **API é”™è¯¯ç‡** - ç™¾åˆ†æ¯”è¶‹åŠ¿
4. **æ´»è·ƒè¿æ¥æ•°** - ä¼šè¯å’Œ WebSocket
5. **LLM è¯·æ±‚é€Ÿç‡** - æŒ‰æ¨¡å‹å’ŒçŠ¶æ€
6. **Agent æ‰§è¡Œè€—æ—¶** - P50/P95 åˆ†ä½æ•°
7. **å†…å­˜ä½¿ç”¨ç‡** - ç™¾åˆ†æ¯” gauge
8. **CPU ä½¿ç”¨ç‡** - ç™¾åˆ†æ¯” gauge
9. **Redis è¿æ¥æ•°** - å®æ—¶è¿æ¥æ•°
10. **å†…å­˜ä½¿ç”¨é‡** - å­—èŠ‚æ•°

---

## ğŸš¨ å‘Šè­¦è§„åˆ™

**é¢„å®šä¹‰å‘Šè­¦ï¼š**

| å‘Šè­¦åç§° | æ¡ä»¶ | çº§åˆ« |
|----------|------|------|
| HighErrorRate | é”™è¯¯ç‡ > 5% (5åˆ†é’Ÿ) | warning |
| SlowResponseTime | P95 > 1ç§’ (10åˆ†é’Ÿ) | warning |
| HighLLMErrorRate | LLM å¤±è´¥ç‡ > 10% (5åˆ†é’Ÿ) | critical |
| HighMemoryUsage | å†…å­˜ä½¿ç”¨ç‡ > 80% (10åˆ†é’Ÿ) | warning |
| HighAgentFailureRate | Agent å¤±è´¥ç‡ > 20% (10åˆ†é’Ÿ) | warning |

---

## ğŸ”§ é…ç½®é¡¹

### ç¯å¢ƒå˜é‡

```bash
# ELK é…ç½®
KIKI_ELK_ENABLED=true
KIKI_ELK_HOST=localhost
KIKI_ELK_PORT=5044
KIKI_ELK_TIMEOUT=5.0
KIKI_ELK_MAX_RETRIES=3
KIKI_ELB_FALLBACK_ENABLED=true

# é™æµé…ç½®
KIKI_RATE_LIMIT_ENABLED=true
KIKI_RATE_LIMIT_DEFAULT_RATE=10.0
KIKI_RATE_LIMIT_DEFAULT_BURST=50
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. æ—¥å¿—è®°å½•

```python
from app.observability.logging import get_logger

logger = get_logger(__name__)

# ç»“æ„åŒ–æ—¥å¿—
logger.info(
    "user_login",
    user_id=user.id,
    ip=request.client.host,
)

# å¼‚å¸¸æ—¥å¿—
try:
    ...
except Exception as e:
    logger.exception(
        "operation_failed",
        operation="create_agent",
        user_id=user.id,
    )
```

### 2. é™æµç­–ç•¥

```python
# èŠå¤©æ¥å£ï¼šä½é¢‘æ¬¡ï¼Œå…è®¸ä¸­ç­‰çªå‘
"/chat": rate=0.5/s, burst=10

# API æ¥å£ï¼šé«˜é¢‘æ¬¡ï¼Œå…è®¸å¤§çªå‘
"/api": rate=10/s, burst=100

# æ³¨å†Œ/ç™»å½•ï¼šä½é¢‘æ¬¡ï¼Œå°çªå‘
"/auth": rate=0.1/s, burst=5
```

### 3. ç¼“å­˜ç­–ç•¥

```python
# çƒ­æ•°æ®ï¼šé•¿ TTLï¼Œå°æŠ–åŠ¨
user_profile: ttl=3600, jitter=5%

# æ¸©æ•°æ®ï¼šä¸­ç­‰ TTL
search_result: ttl=300, jitter=10%

# å†·æ•°æ®ï¼šçŸ­ TTLï¼Œå¤§æŠ–åŠ¨
statistic_data: ttl=60, jitter=20%
```

### 4. WebSocket è¿æ¥ç®¡ç†

```python
# å¿ƒè·³ä¿æ´»
setInterval(() => {
  ws.send(JSON.stringify({ action: 'ping' }));
}, 30000);

# é‡è¿æœºåˆ¶
ws.onclose = () => {
  setTimeout(() => reconnect(), 1000);
};
```

---

## ğŸªŸ çª—å£è®°å¿†ï¼ˆWindow Memoryï¼‰

### æ¦‚è¿°

çª—å£è®°å¿†æœºåˆ¶åŸºäº LangChain çš„ `trim_messages` å®ç° Token çº§åˆ«çš„æ»‘åŠ¨çª—å£ï¼Œç¡®ä¿å¯¹è¯å†å²ä¸è¶…è¿‡ LLM çš„ä¸Šä¸‹æ–‡é™åˆ¶ã€‚

**æ ¸å¿ƒç‰¹æ€§ï¼š**
- Token çº§åˆ«é™åˆ¶ï¼ˆè€Œéç®€å•çš„æ¶ˆæ¯æ•°é‡ï¼‰
- æ”¯æŒå¤šç§ä¿®å‰ªç­–ç•¥ï¼ˆlast/firstï¼‰
- ç¡®ä¿å¯¹è¯è¾¹ç•Œå®Œæ•´æ€§
- æ”¯æŒè‡ªå®šä¹‰ token è®¡æ•°å™¨

**å‚è€ƒå®ç°ï¼š** `week07/p07-windowMEM.py`

### åŸºç¡€ä½¿ç”¨

```python
from app.agent.memory import create_pre_model_hook

# åˆ›å»º pre_model_hook
hook = create_pre_model_hook(
    max_tokens=384,        # æœ€å¤§ Token æ•°
    strategy="last",       # ä¿ç•™æœ€æ–°çš„æ¶ˆæ¯
    start_on="human",      # ä»äººç±»æ¶ˆæ¯å¼€å§‹
    end_on=("human", "tool"),  # åœ¨äººç±»æˆ–å·¥å…·æ¶ˆæ¯ç»“æŸ
)

# ç”¨äº LangGraph
builder = StateGraph(AgentState)
builder.add_node(
    "agent",
    model_node,
    pre_model_hook=hook,  # æ·»åŠ é’©å­
)
```

### é«˜çº§ä½¿ç”¨

```python
from app.agent.memory import WindowMemoryManager, TokenCounterType

# åˆ›å»ºç®¡ç†å™¨
manager = WindowMemoryManager(
    max_tokens=1000,
    strategy="last",
    token_counter_type=TokenCounterType.APPROXIMATE,
    preserve_system=True,
)

# ä¿®å‰ªæ¶ˆæ¯
trimmed = manager.trim_messages(messages)

# è·å–ç»Ÿè®¡
stats = manager.get_stats()
print(f"æ€»ä¿®å‰ªæ¬¡æ•°: {stats['total_trims']}")
print(f"å¹³å‡ç§»é™¤ Token: {stats['avg_tokens_removed']}")
```

### ä¾¿æ·å‡½æ•°

```python
from app.agent.memory import (
    create_chat_hook,      # èŠå¤©ä¸“ç”¨é’©å­
    trim_state_messages,   # ç›´æ¥ä¿®å‰ªçŠ¶æ€æ¶ˆæ¯
    get_window_memory_manager,  # è·å–å…¨å±€ç®¡ç†å™¨
)

# èŠå¤©åœºæ™¯
hook = create_chat_hook(max_tokens=500)

# ç›´æ¥ä¿®å‰ª
trimmed = trim_state_messages(state, max_tokens=384)
```

---

## ğŸ”„ å·¥å…·é‡è¯•ï¼ˆTool Retryï¼‰

### æ¦‚è¿°

å·¥å…·é‡è¯•æœºåˆ¶åŸºäº LangGraph çš„ `retry` å‚æ•°å®ç°è‡ªåŠ¨é‡è¯•ï¼Œæ”¯æŒæŒ‡æ•°é€€é¿ç®—æ³•é¿å…é›ªå´©ã€‚

**æ ¸å¿ƒç‰¹æ€§ï¼š**
- å¯é…ç½®çš„é‡è¯•ç­–ç•¥ï¼ˆæ¬¡æ•°ã€é—´éš”ã€é€€é¿å› å­ï¼‰
- æ”¯æŒæŒ‡å®šå¯é‡è¯•çš„å¼‚å¸¸ç±»å‹
- æŒ‡æ•°é€€é¿ç®—æ³•
- æ”¯æŒè‡ªå®šä¹‰é‡è¯•æ¡ä»¶

**å‚è€ƒå®ç°ï¼š** `week07/p13-toolRetry.py`

### å¼‚å¸¸ç±»å‹

```python
from app.agent.retry import (
    RetryableError,          # å¯é‡è¯•é”™è¯¯åŸºç±»
    NetworkError,            # ç½‘ç»œé”™è¯¯
    RateLimitError,          # é€Ÿç‡é™åˆ¶
    ResourceUnavailableError,  # èµ„æºä¸å¯ç”¨
    TemporaryServiceError,   # ä¸´æ—¶æœåŠ¡é”™è¯¯
    ToolExecutionError,      # å·¥å…·æ‰§è¡Œé”™è¯¯ï¼ˆä¸é‡è¯•ï¼‰
)
```

### é‡è¯•ç­–ç•¥

```python
from app.agent.retry import RetryPolicy, RetryStrategy

policy = RetryPolicy(
    max_attempts=3,                    # æœ€å¤§å°è¯•æ¬¡æ•°
    retry_on=(NetworkError, RateLimitError),  # å¯é‡è¯•å¼‚å¸¸
    strategy=RetryStrategy.EXPONENTIAL_BACKOFF,  # æŒ‡æ•°é€€é¿
    initial_interval=1.0,              # åˆå§‹é—´éš” 1 ç§’
    backoff_factor=2.0,                # é€€é¿å› å­
    max_interval=60.0,                 # æœ€å¤§é—´éš” 60 ç§’
    jitter=True,                       # å¯ç”¨æŠ–åŠ¨
    jitter_percent=0.1,                # æŠ–åŠ¨ Â±10%
)
```

### è£…é¥°å™¨æ–¹å¼

```python
from app.agent.retry import with_retry

@with_retry(max_attempts=3)
async def risky_operation():
    # å¯èƒ½å¤±è´¥çš„æ“ä½œ
    response = await api_call()
    return response

# å¸¦é‡è¯•å›è°ƒ
async def on_retry_fn(error, attempt):
    logger.warning(f"é‡è¯• {attempt}: {error}")

@with_retry(policy=policy, on_retry=on_retry_fn)
async def operation_with_callback():
    pass
```

### ä¸Šä¸‹æ–‡ç®¡ç†å™¨

```python
from app.agent.retry import RetryContext

policy = RetryPolicy(max_attempts=3)

async with RetryContext(policy) as retry:
    result = await retry.attempt(risky_function)
```

### LangGraph èŠ‚ç‚¹

```python
from app.agent.retry import create_retryable_node

async def my_tool_node(state: AgentState) -> dict:
    # å·¥å…·é€»è¾‘
    return {"messages": [...]}

# åˆ›å»ºå¯é‡è¯•èŠ‚ç‚¹
retryable_node = create_retryable_node(
    my_tool_node,
    policy=RetryPolicy(max_attempts=3)
)

builder.add_node("my_tool", retryable_node)
```

### ä¾¿æ·å‡½æ•°

```python
from app.agent.retry import execute_with_retry

result = await execute_with_retry(
    llm.ainvoke,
    messages,
    policy=RetryPolicy(max_attempts=3)
)
```

### é‡è¯•ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | æè¿° | å»¶è¿Ÿè®¡ç®— | é€‚ç”¨åœºæ™¯ |
|------|------|----------|----------|
| IMMEDIATE | ç«‹å³é‡è¯• | 0 | æµ‹è¯•ç¯å¢ƒ |
| FIXED_INTERVAL | å›ºå®šé—´éš” | initial_interval | ç¨³å®šæœåŠ¡ |
| LINEAR_BACKOFF | çº¿æ€§é€€é¿ | initial_interval Ã— attempt | è½»å¾®è¿‡è½½ |
| EXPONENTIAL_BACKOFF | æŒ‡æ•°é€€é¿ | initial_interval Ã— backoff_factor^(attempt-1) | é«˜å¹¶å‘ |

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [ELK Stack å®˜æ–¹æ–‡æ¡£](https://www.elastic.co/guide/)
- [Prometheus æœ€ä½³å®è·µ](https://prometheus.io/docs/practices/)
- [ä»¤ç‰Œæ¡¶ç®—æ³•è¯¦è§£](https://en.wikipedia.org/wiki/Token_bucket)
- [WebSocket RFC 6455](https://tools.ietf.org/html/rfc6455)
- [LangChain trim_messages](https://python.langchain.com/docs/how_to/trim_messages/)
- [LangGraph é‡è¯•æœºåˆ¶](https://langchain-ai.github.io/langgraph/reference/checkpoints/#retry-policy)
