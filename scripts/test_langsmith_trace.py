"""LangSmith è¿½è¸ªç‹¬ç«‹æµ‹è¯•è„šæœ¬

è¿è¡Œæ­¤è„šæœ¬å°†åœ¨ LangSmith Studio åˆ›å»ºé¡¹ç›®å¹¶è®°å½•è¿½è¸ªã€‚
ç”¨äºéªŒè¯ langsmith-fetch è°ƒè¯•åŠŸèƒ½ã€‚

è¿è¡Œæ–¹å¼:
    uv run python scripts/test_langsmith_trace.py

ç¯å¢ƒå˜é‡:
    LANGCHAIN_TRACING_V2=true
    LANGCHAIN_API_KEY=your_key_here
"""

import os

# ç¡®ä¿ LangSmith ç¯å¢ƒå˜é‡å·²è®¾ç½®
# æ³¨æ„ï¼šLANGCHAIN_API_KEY éœ€è¦ä»ç¯å¢ƒå˜é‡è®¾ç½®ï¼Œä¸è¦ç¡¬ç¼–ç 
os.environ.setdefault("LANGCHAIN_TRACING_V2", "true")
if "LANGCHAIN_API_KEY" not in os.environ:
    raise ValueError("è¯·è®¾ç½® LANGCHAIN_API_KEY ç¯å¢ƒå˜é‡")
os.environ.setdefault("LANGCHAIN_PROJECT", "kiki-agent")

from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage


def test_simple_chat():
    """ç®€å•çš„èŠå¤©æµ‹è¯•ï¼Œç”Ÿæˆ LangSmith è¿½è¸ª"""
    print("ğŸ”¥ å¼€å§‹æµ‹è¯• LangSmith è¿½è¸ª...")
    print(f"ğŸ“Š é¡¹ç›®: {os.environ['LANGCHAIN_PROJECT']}")
    print(f"ğŸ”‘ Tracing: {os.environ['LANGCHAIN_TRACING_V2']}")
    print("-" * 50)

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„ LLM è°ƒç”¨
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ Anthropicï¼Œå¦‚æœæ‚¨æ²¡æœ‰ API key ä¼šå¤±è´¥
    # ä½†è¿½è¸ªä»ä¼šä¸Šä¼ åˆ° LangSmith
    try:
        llm = ChatAnthropic(
            model="claude-3-5-haiku-20241022",
            temperature=0.7,
        )

        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ã€‚"),
            HumanMessage(content="ç”¨ä¸€å¥è¯ä»‹ç» Pythonã€‚"),
        ]

        print("ğŸ“¤ å‘é€è¯·æ±‚åˆ° LLM...")
        response = llm.invoke(messages)

        print("-" * 50)
        print("âœ… æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“¥ å“åº”: {response.content}")
        print("\nğŸ”— æŸ¥çœ‹ LangSmith Studio:")
        print(f"   https://smith.langchain.com/?projectId={os.environ['LANGCHAIN_PROJECT']}")

    except Exception as e:
        print(f"âš ï¸  LLM è°ƒç”¨å¤±è´¥: {e}")
        print("ğŸ’¡ å¦‚æœæ˜¯ API key é—®é¢˜ï¼Œè¿½è¸ªå¯èƒ½ä»å·²ä¸Šä¼ åˆ° LangSmith")


def test_with_structured_output():
    """æµ‹è¯•ç»“æ„åŒ–è¾“å‡ºï¼Œå±•ç¤ºæ›´å¤æ‚çš„è¿½è¸ª"""
    print("\nğŸ”§ æµ‹è¯•ç»“æ„åŒ–è¾“å‡º...")

    try:
        from langchain_anthropic import ChatAnthropic
        from langchain_core.messages import HumanMessage

        llm = ChatAnthropic(
            model="claude-3-5-haiku-20241022",
            temperature=0,
        )

        # ä½¿ç”¨ with_structured_output ç”Ÿæˆå·¥å…·è°ƒç”¨è¿½è¸ª
        structured_llm = llm.with_structured_output(
            {
                "name": "str",
                "description": "str",
                "steps": "list[str]",
            }
        )

        response = structured_llm.invoke(
            [
                HumanMessage(
                    content="ç”¨ JSON æ ¼å¼å‘Šè¯‰æˆ‘å¦‚ä½•æ³¡ä¸€æ¯èŒ¶ï¼ŒåŒ…å« nameã€description å’Œ steps"
                )
            ]
        )

        print("âœ… ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“¥ å“åº”: {response}")

    except Exception as e:
        print(f"âš ï¸  ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("  LangSmith è¿½è¸ªæµ‹è¯•")
    print("=" * 50)

    # è¿è¡Œæµ‹è¯•
    test_simple_chat()
    test_with_structured_output()

    print("\n" + "=" * 50)
    print("ğŸ“ ä½¿ç”¨ langsmith-fetch æŸ¥çœ‹è¿½è¸ª:")
    print("   uv run langsmith-fetch traces --limit 5 --format pretty")
    print("=" * 50)


if __name__ == "__main__":
    main()
